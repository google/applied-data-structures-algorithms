{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y55tIGD1XuhA"
      },
      "source": [
        "# Big-O Math Deep Dive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubnskqLBXx6j"
      },
      "source": [
        "## Lesson Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08x79eK9vahh"
      },
      "source": [
        "*NOTE: **This lesson is entirely optional.** The content covers the mathematics behind much of the complexity analysis in the standard material. The questions are extremely difficult and out of scope.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9H1fVKKbX7Zd"
      },
      "source": [
        "**Limit notation**\n",
        "\n",
        "When analyzing the efficiency of an algorithm, it is important to understand how the time and space requirements of the algorithm change as it handles more data. For example, suppose you have an algorithm for sorting integers that you want to deploy to production. You should know how long it takes and how much memory it requires both for small $n$ (where $n$ is the number of integers to sort) and also for increasingly large $n$, or as $n \\to \\infty$.\n",
        "\n",
        "You may have seen **limit notation** such as this before. If you haven't, don't worry. Writing $n \\to \\infty$ is just shorthand for writing \"as $n$ gets larger and larger\".\n",
        "\n",
        "\u003e A statement $S(n)$ is true as $n \\to \\infty$ if there exists an $N$ such that $S(n)$ is true for all $n \\geq N$.\n",
        "\n",
        "Remember that it is not sufficient for the statement to be true *at* a large value of $N$, but for all values of $n \\geq N$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7kjFxujewwV"
      },
      "source": [
        "**Conceptual definition**\n",
        "\n",
        "In a mathematical context, big-O notation is used to compare the growth of two functions. The growth of a function is, conceptually, how the function behaves as the input increases towards infinity.\n",
        "\n",
        "\u003e $f(n) \\in O(g(n))$ if $f(n)$ grows at most as quickly as $g(n)$, as $n \\to \\infty$.\n",
        "\n",
        "$O(g(n))$ is the set of all of the functions that grow at most as quickly as $g(n)$. The $\\in$ notation is used to denote membership in a set, and $f(n)$ is one of the functions in the set.\n",
        "\n",
        "In most contexts in computer science, it is more common to write $f(n) = O(g(n))$ than $f(n) \\in O(g(n))$. Therefore throughout this lesson, we will use $=$ instead of $\\in$ for big-O comparisons."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SothqOd-Ewz9"
      },
      "source": [
        "**Mathematical definition 1**\n",
        "\n",
        "The mathematical definition of big-O is just a formalization of the conceptual definition above.\n",
        "\n",
        "\u003e $f(n) \\in O(g(n))$ as $n \\to \\infty$ if, for any given $N$, there exists a positive number $M$ such that $|f(n)| \\leq Mg(n)$ for all $n \\geq N$.\n",
        "\n",
        "Using this definition, $n^2 = O(2^n)$ because, for any $N$, you can find an $M$ such that $n^2 \\leq M \\cdot 2^n$ for all $n \\geq N$. For example:\n",
        "\n",
        "- If $N = 3$, you can choose $M = 2$ so that $n^2 \\leq 2 \\cdot 2^n$ for all $n \\geq 3$. (In fact, there are smaller values of $M$ that you could choose. $M = 1.5$ would work too, as would any value $M \\geq \\frac{9}{8}$.)\n",
        "- For any $N \\geq 4$, you can choose $M = 1$ so that $n^2 \\leq 1 \\cdot 2^n$ for all $n \\geq 4$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvVYlFtneppg"
      },
      "source": [
        "**Mathematical definition 2**\n",
        "\n",
        "This alternate mathematical definition of big-O may be simpler to understand, but contains more rigorous notation.\n",
        "\n",
        "\u003e $f(n) \\in O(g(n))$ if $\\lim\\limits_{n \\to \\infty} \\frac{f(n)}{g(n)} \u003c \\infty$.\n",
        "\n",
        "- $\\lim\\limits_{n \\to \\infty} \\frac{f(n)}{g(n)}$ denotes the value that $\\frac{f(n)}{g(n)}$ approaches or becomes closer and closer to as $n \\to \\infty$.\n",
        "- $\u003c \\infty$ just means that the limit should be a finite number.\n",
        "\n",
        "Here's another way to write this:\n",
        "\n",
        "\u003e For any $N$, there exists an $M$ such that $\\frac{f(n)}{g(n)} \u003c M$ for all $n \u003e N$.\n",
        "\n",
        "This definition means that the ratio of $f(n)$ to $g(n)$ must *not* grow towards infinity as $n \\to \\infty$. For example, $\\lim\\limits_{n \\to \\infty} \\frac{n^2}{2^n} = 0$, so $n^2 = O(2^n)$.\n",
        "\n",
        "But the limit of the ratio does not need to be zero. Even if $f(n) \u003e g(n)$ for all $n$, it can still be true that $f(n) = O(g(n))$, as long as $f(n)$ does not *grow* faster than $g(n)$. For example, $100n = O(n)$, since $\\lim\\limits_{n \\to \\infty} \\frac{100n}{n} = \\lim\\limits_{n \\to \\infty} 100 = 100$. This can also be shown using the initial definition of big-O by choosing $M = 100$.\n",
        "\n",
        "As a general rule, constants can be ignored when applying big-O notation. More formally, $M f(n)$ always has the same big-O properties as $f(n)$ itself, so you can ignore $M$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDGsWpmuxfZc"
      },
      "source": [
        "**Using derivatives to compare growth**\n",
        "\n",
        "One of the most effective ways to examine a function's growth is through its **derivative**. The derivative of a function $f(n)$ is itself a function, denoted $f'(n)$ that tells you the rate of change of $f(n)$. ([Here is a quick guide](https://www.mathsisfun.com/calculus/derivatives-rules.html) to derivatives of common functions.) For example, if $f(n) = n^2$ and $g(n) = 2^n$,\n",
        "\n",
        "\\begin{align*}\n",
        "f'(n) \u0026= 2n \\\\\n",
        "g'(n) \u0026= \\ln(2) \\cdot 2^n \\\\\n",
        "\\end{align*}\n",
        "\n",
        "where $\\ln$ is the [natural logarithm](https://en.wikipedia.org/wiki/Natural_logarithm). Remember that constants like $\\ln(2)$ can be ignored in big-O analysis. \n",
        "\n",
        "While it may be harder to tell by inspection that $g(n)$ grows faster than $f(n)$, it should be more straightforward to see that $g'(n) \u003e f'(n)$ for all large $n$, and therefore $f(n) = O(g(n))$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKYtlMwg1sqv"
      },
      "source": [
        "## Assessment Questions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgXlyU0KSbcu"
      },
      "source": [
        "## Question 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gl0X3GW_2e10"
      },
      "source": [
        "Using derivatives, relate $f(n) = \\sqrt n$ and $g(n) = \\log_2(n)$ using big-O notation. See *Understanding Limiting Behavior* above for an example."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9r1Qpr4JSsVm"
      },
      "source": [
        "### Hint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-rzcxVrStlN"
      },
      "source": [
        "Remember that $\\sqrt n = n^{\\frac{1}{2}}$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yl7NrtHw3a7G"
      },
      "source": [
        "### Solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17t14S4B3hnw"
      },
      "source": [
        "Using [this guide for calculating derivatives](https://www.mathsisfun.com/calculus/derivatives-rules.html):\n",
        "\n",
        "\\begin{align*}\n",
        "f'(n) \u0026= \\frac{1}{2\\sqrt n} \\\\\n",
        "g'(n) \u0026= \\frac{1}{n \\ln(2)} \\\\\n",
        "\\end{align*}\n",
        "\n",
        "In general for large $n$, $\\sqrt{n} \u003c n$, so $\\frac{1}{\\sqrt n} \u003e \\frac{1}{n}$. As always, constants like $\\frac{1}{2}$ and $\\frac{1}{\\ln(2)}$ can be ignored. Therefore, since $f'(n) \u003e g'(n)$ for all large $n$, $g(n) = O(f(n))$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yv91ZRZ7cjU4"
      },
      "source": [
        "## Question 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2YN_Pz-Di5_"
      },
      "source": [
        "Use any method to show that $f(n) = n^{\\frac{3}{2}}$ grows slower than $g(n) = n\\log_2(n)$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MvEqxeXcvPO"
      },
      "source": [
        "### Solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKVHqbD8LS7Q"
      },
      "source": [
        "There are a few ways to do this. The first way is a heuristic. As per the common complexities table in the Lesson Overview, $\\sqrt{n}$ grows faster than $\\log_2(n)$, so if both expressions are multipled by $n$, it follows that $n^{\\frac{3}{2}}$ grows faster than $n \\log_2(n)$.\n",
        "\n",
        "A second more formal approach uses derivatives. As seen in the lesson that defines big-O notation, if we can show that $f'(n) \u003e g'(n)$ for all large values of $n$, then $f$ grows faster than $g$. Given $f$ and $g$ defined as in the question, we have\n",
        " \n",
        "\\begin{align*}\n",
        "f'(n) \u0026= \\frac{3}{2} n^{\\frac{1}{2}} \\\\\n",
        "\u0026= O(\\sqrt{n}). \\\\\n",
        "\\end{align*}\n",
        "\n",
        "Using [log laws](https://en.wikipedia.org/wiki/List_of_logarithmic_identities#Using_simpler_operations), $\\log_2(n) = \\frac{\\ln(n)}{\\ln(2)}$. Thus we can rewrite $g$ as\n",
        "\n",
        "\\begin{align*}\n",
        "g(n) \u0026= \\frac{1}{\\ln(2)} n \\ln(n). \\\\\n",
        "\\end{align*}\n",
        "\n",
        "Using the chain rule to calculate the derivative of $g$ yields\n",
        "\n",
        "\\begin{align*}\n",
        "g'(n) \u0026= \\frac{1}{\\ln(2)} \\left( \\ln(n) \\cdot 1 + \\frac{1}{n} \\cdot n \\right) \\\\\n",
        "\u0026= \\frac{1}{\\ln(2)}(\\ln(n)+1) \\\\\n",
        "\u0026= \\log_2(n) + \\frac{1}{\\ln(2)} \\\\\n",
        "\u0026= O(\\log_2(n)). \\\\\n",
        "\\end{align*}\n",
        "\n",
        "As shown via derivatives in an exercise from the big-O definition lesson, $\\sqrt{n}$ grows faster than $\\log_2(n)$ for large $n$, so eventually for large $n$ $\\sqrt{n} \u003e \\log_2(n)$. Therefore, since $f'(n) \u003e g'(n)$ for large $n$, $f$ grows faster than $g$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18iplSYkSiS4"
      },
      "source": [
        "## Question 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5rFE0NMSufk"
      },
      "source": [
        "[Advanced] Relate $f(n) = 100n^{100}$ and $g(n) = 2^n$ using big-O notation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FS1F2TMSTaiG"
      },
      "source": [
        "### Hint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdo01UPtTcEt"
      },
      "source": [
        "What happens if you take the derivative over and over again?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFmgw8HlS0du"
      },
      "source": [
        "### Solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NH9jFNS2UDkZ"
      },
      "source": [
        "This can be simplified by recognizing that constants can be ignored, so we can compare $f(n) = n^{100}$ to $g(n) = 2^n$. We covered in the Lesson Overview that $n^2 = O(2^n)$, so how does that change as the exponent of $n$ changes?\n",
        "\n",
        "These functions exemplify why we can't always solely use a visualization. See below for a graph of both functions on a log scale for values up to 100. For this range, it appears as if $n^{100}$ is growing much faster than $2^n$. If we expand the $x$-axis to larger values of $n$, we may hit computational issues. ($100^{100}$ is already a very large number, equal to 2 [googol](https://en.wikipedia.org/wiki/Googol).)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uYuKV9yyUssn"
      },
      "outputs": [],
      "source": [
        "N = 100\n",
        "n = [i for i in range(1, N+1)]\n",
        "\n",
        "f = [i**100 for i in n]\n",
        "g = [2**i for i in n]\n",
        "\n",
        "plt.plot(n, f, color='blue', label='n^100')\n",
        "plt.plot(n, g, color='red', label='2^n')\n",
        "plt.yscale('log')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9oWnGOMHV1Oq"
      },
      "source": [
        "For this comparison, let's try taking the derivative:\n",
        "\n",
        "\\begin{align*}\n",
        "f'(n) \u0026= 100n^{99} \\\\\n",
        "g'(n) \u0026= \\ln(2) \\cdot 2^n \\\\\n",
        "\\end{align*}\n",
        "\n",
        "And the second derivative:\n",
        "\n",
        "\\begin{align*}\n",
        "f''(n) \u0026= 9900n^{98} \\\\\n",
        "g''(n) \u0026= \\ln(2)^2 \\cdot 2^n \\\\\n",
        "\\end{align*}\n",
        "\n",
        "Let $f^{(m)}(n)$ be the $m^{\\textrm{th}}$ derivative of $f(n)$. By repeating this, we will see that:\n",
        "\n",
        "\\begin{align*}\n",
        "f^{(101)}(n) \u0026= 0 \\\\\n",
        "g^{(101)}(n) \u0026= \\ln(2)^ {101} \\cdot 2^n \\\\\n",
        "\\end{align*}\n",
        "\n",
        "So while all derivatives of $g(n)$ grow exponentially, the derivatives of $f(n)$ eventually have no growth. We can deduce from this that while $f(n)$ may have larger values than $g(n)$ for some $n$, eventually $g(n)$ will grow faster than $f(n)$, so $n^{100} = O(2^n)$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEAl8qdBSkFr"
      },
      "source": [
        "## Question 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBAFxUfOZK_b"
      },
      "source": [
        "[Advanced] Relate $f(n)$ to $g(n)$ where:\n",
        "\n",
        "\\begin{align*}\n",
        "f(n) \u0026= 0.135 \\cdot 2^{2n+3} + 10^{100} \\sqrt n - 56 \\\\\n",
        "g(n) \u0026= 10n^{1000} + 9n^{999} + 8\\pi \\\\\n",
        "\\end{align*}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-jwW9WvTwzT"
      },
      "source": [
        "### Hint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-t02mDBkTtU5"
      },
      "source": [
        "When a function is the sum of many functions, it only grows as fast as its fastest growing term. This can be formally stated as follows:\n",
        "\n",
        "\u003e If $f(n) = \\sum\\limits_{i=1}^n f_i(n)$ and there exists some $m$ such that $f_i(n) = O(f_m(n))$ for all $i$, then $f(n) = O(f_m(n))$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCNkp-OtS1dN"
      },
      "source": [
        "### Solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5VswXqTboMP"
      },
      "source": [
        "First, let's drastically simplify this problem by ignoring the multiplicative and additive constants.\n",
        "\n",
        "\\begin{align*}\n",
        "f(n) \u0026= 0.135 \\cdot 2^{2n+3} + 10^{100} \\sqrt n - 56 \\\\\n",
        "\u0026= O(2^{2n+3} + \\sqrt n) \\\\\n",
        "\u0026= O(2^3 \\cdot (2^2)^n + \\sqrt n) \\\\\n",
        "\u0026= O(4^n + \\sqrt n) \\\\\n",
        "g(n) \u0026= 10n^{1000} + 9n^{999} + 8\\pi \\\\\n",
        "\u0026= O(n^{1000} + n^{999}) \\\\\n",
        "\\end{align*}\n",
        "\n",
        "Now we can compare $f(n) = 4^n + \\sqrt n$ to $g(n) = n^{1000} + n^{999}$.\n",
        "\n",
        "Using the hint, if $f(n)$ can be broken down into a sum of other functions, then we only need to know which of those functions grows the fastest. Once we find that function $f_m(n)$, we know that $f(n) = O(f_m(n))$.\n",
        "\n",
        "Using similar approaches to above (either by derivatives or a visualization), we can show that $\\sqrt n = O(n^2)$, and as we saw in the Lesson Overview, $n^2 = O(2^n)$. It should then make intuitive sense that $2^n = O(4^n)$ since $4^n = (2^n)^2$, therefore $\\sqrt n = O(n^2) = O(2^n) = O(4^n)$. Using the above logic, $f(n) = O(4^n)$.\n",
        "\n",
        "Since $n^{1000} = n \\cdot n^{999}$, it should make sense that $n^{999} = O(n^{1000})$, therefore $g(n) = O(n^{1000})$. As we saw in Question 3, exponential growth beats any polynomial growth in the long run, so $n^{1000} = O(4^n)$, and $f(n) = O(g(n))$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJrgzaA-UwTB"
      },
      "source": [
        "## Question 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRyUPOYH-rFg"
      },
      "source": [
        "Show that if $f(n) \\to \\infty$ as $n \\to \\infty$, then $f(n) + K = O(f(n))$ for a constant $K$.\n",
        "\n",
        "This is a formalization of what you have already seen above, namely that additive constants can be ignored for big-O comparisons. For example, $O(n^2 + 3) = O(n^2)$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jd4TSqSp1AIc"
      },
      "source": [
        "### Solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhjMf98W_JHn"
      },
      "source": [
        "For this example, it is probably easiest to use the second definition of big-O. We need to show that if $f(n) \\to \\infty$ as $n \\to \\infty$ then $\\lim\\limits_{n \\to \\infty} \\frac{f(n) + K}{f(n)} \u003c \\infty$.\n",
        "\n",
        "\\begin{align*}\n",
        "\\lim_{n \\to \\infty} \\frac{f(n) + K}{f(n)} \u0026= \\lim_{n \\to \\infty} \\left( \\frac{f(n)}{f(n)} + \\frac{K}{f(n)} \\right) \\\\\n",
        "\u0026= \\lim_{n \\to \\infty} \\left( 1 + \\frac{K}{f(n)} \\right) \\\\\n",
        "\u0026= \\lim_{n \\to \\infty} 1 + \\lim_{n \\to \\infty} \\frac{K}{f(n)} \\\\\n",
        "\u0026= 1 + K \\lim_{n \\to \\infty} \\frac{1}{f(n)} \\\\\n",
        "\\end{align*}\n",
        "\n",
        "Since $f(n) \\to \\infty$ as $n \\to \\infty$, $\\frac{1}{f(n)} \\to 0$ as $n \\to \\infty$. Therefore the above expression reduces to 1, which is $\u003c \\infty$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OFnqW7eUzfo"
      },
      "source": [
        "## Question 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4kjXOzJZJ_N"
      },
      "source": [
        "Show that if $Kf(n) = O(f(n))$ for a constant $K$.\n",
        "\n",
        "Again, this is a formalization of what you have seen above, that multiplicative constants can be ignored for big-O comparisons. For example, $O(3n^2) = O(n^2)$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-BG70vtVG5r"
      },
      "source": [
        "### Solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRRfyltcZe3m"
      },
      "source": [
        "Again, this is most easily shown using the second mathematical definition above. We need to show that $\\lim\\limits_{n \\to \\infty} \\frac{Kf(n)}{f(n)} \u003c \\infty$.\n",
        "\n",
        "\\begin{align*}\n",
        "\\lim_{n \\to \\infty} \\frac{Kf(n)}{f(n)} \u0026= K \\lim\\limits_{n \\to \\infty} \\frac{f(n)}{f(n)} \\\\\n",
        "\u0026= K \\lim_{n \\to \\infty} 1 \\\\\n",
        "\u0026= K \\\\\n",
        "\\end{align*}\n",
        "\n",
        "Since $K$ is a constant, it is $\u003c \\infty$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8-ka488U3fp"
      },
      "source": [
        "## Question 7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQ46OXERaEX9"
      },
      "source": [
        "Show that if $f_1(n) = O(g_1(n))$ and $f_2(n) = O(g_2(n))$, then $f_1(n) f_2(n) = O(g_1(n) g_2(n))$.\n",
        "\n",
        "This is an important result since it shows that if you can break up a function into distinct parts, you can analyze the big-O notation of each part independently, then take the product. For example, $O(n^2 2^n) = O(n^2) O(2^n)$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-57LozH3VHqr"
      },
      "source": [
        "### Solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FizvQKja7mb"
      },
      "source": [
        "This is easiest to show when using the first definition of big-O.\n",
        "\n",
        "- $f_1(n) = O(g_1(n))$ therefore there exists $M_1$ such that $|f_1(n)| \\leq M_1g_1(n)$ for all $n \\geq N_1$.\n",
        "- $f_2(n) = O(g_2(n))$ therefore there exists $M_2$ such that $|f_2(n)| \\leq M_2g_2(n)$ for all $n \\geq N_2$.\n",
        "\n",
        "We need to show that for any given $N$, there exists an $M$ such that $|f_1(n) f_2(n)| \\leq Mg_1(n)g_2(n)$.\n",
        "\n",
        "Since the [absolute value of a product is the produce of absolute values](https://proofwiki.org/wiki/Absolute_Value_of_Product), we know that:\n",
        "\n",
        "$$|f_1(n) f_2(n)| = |f_1(n)||f_2(n)|$$\n",
        "\n",
        "Plugging in the inequalities above, we have that for $n \\geq \\max(N_1, N_2)$:\n",
        "\n",
        "\\begin{align*}\n",
        "|f_1(n)||f_2(n)| \u0026\\leq M_1g_1(n) M_2 g_2(n) \\\\\n",
        "\u0026= M_1M_2 g_1g_2(n)\n",
        "\\end{align*}\n",
        "\n",
        "We can therefore choose $M = M_1M_2$ and $n = \\max(N_1, N_2)$ to satisfy the inequality to show that $f_1(n) f_2(n) = O(g_1(n) g_2(n))$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RnxdDplU5io"
      },
      "source": [
        "## Question 8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYlLZIdl03NM"
      },
      "source": [
        "Show that if $f_1(n) = O(g_1(n))$ and $f_2(n) = O(g_2(n))$ then $f_1(n) + f_2(n) = O(g_1(n) + g_2(n))$.\n",
        "\n",
        "This is another result that you have already seen above. It shows that if a function can be split into a sum of other functions, it only grows as quickly as its fastest growing component. For example, $O(n^2 + 2^n) = O(2^n)$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B25QNhhXVIe9"
      },
      "source": [
        "### Solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i64KEVBX1CBp"
      },
      "source": [
        "This is a similar proof to the solution to Question 3.\n",
        "\n",
        "- $f_1(n) = O(g_1(n))$ therefore there exists $M_1$ such that $|f_1(n)| \\leq M_1g_1(n)$ for all $n \\geq N_1$.\n",
        "- $f_2(n) = O(g_2(n))$ therefore there exists $M_2$ such that $|f_2(n)| \\leq M_2g_2(n)$ for all $n \\geq N_2$.\n",
        "\n",
        "By the [triangle inequality](https://en.wikipedia.org/wiki/Triangle_inequality):\n",
        "\n",
        "$$|f_1(n) + f_2(n)| \\leq |f_1(n)| + |f_2(n)|$$\n",
        "\n",
        "Plugging in the inequalities above, we have that for $n \\geq \\max(N_1, N_2)$:\n",
        "\n",
        "\\begin{align*}\n",
        "|f_1(n)| + |f_2(n)| \u0026\\leq M_1g_1(n) + M_2g_2(n) \\\\\n",
        "\u0026\\leq 2\\max(M_1, M_2) \\max(g_1(n), g_2(n)) \\\\\n",
        "\\end{align*}\n",
        "\n",
        "We have now found the constant $M = 2\\max(M_1M_2)$ to show that $f_1(n) + f_2(n) = O(\\max(g_1(n)g_2(n))$."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "9r1Qpr4JSsVm",
        "Yl7NrtHw3a7G",
        "5MvEqxeXcvPO",
        "FS1F2TMSTaiG",
        "BFmgw8HlS0du",
        "L-jwW9WvTwzT",
        "yCNkp-OtS1dN",
        "Jd4TSqSp1AIc",
        "E-BG70vtVG5r",
        "-57LozH3VHqr",
        "B25QNhhXVIe9"
      ],
      "name": "big_o_math_deep_dive.ipynb",
      "private_outputs": true,
      "provenance": [ ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
